{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This is not entirely my code. It was created by following the tutorial created by Nicholas Renotte on his YouTube video, found here:  https://www.youtube.com/watch?v=2eeYqJ0uBKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Super Mario Bros game\n",
    "import gym_super_mario_bros\n",
    "# Import Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import simplified controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SIMPLE_MOVEMENT` is nice because it restricts which actions our agent can take. Printing the `SIMPLE_MOVEMENT` below, you can see that the options are quite limited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the number of actions if we dont use SIMPLE_MOVEMENT: Discrete(256)\n",
      "Once we have limited the aciton space with SIMPLE_MOVEMENT, mario can only do Discrete(7) actions\n"
     ]
    }
   ],
   "source": [
    "# Setup the environment (the game)\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "print(f'Here is the number of actions if we dont use SIMPLE_MOVEMENT: {env.action_space}')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "print(f'Once we have limited the aciton space with SIMPLE_MOVEMENT, mario can only do {env.action_space} actions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, limiting the action space is beneficial to us as it allows the agent to learn faster when the possible choices of actions it can make are limited. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gex71\\Documents\\repos\\mario-ml\\mario-tutorial.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39msample())\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m# render will show the game on the screen\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     env\u001b[39m.\u001b[39;49mrender()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m env\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\gym\\core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\gym\\core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\nes_py\\nes_env.py:386\u001b[0m, in \u001b[0;36mNESEnv.render\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewer \u001b[39m=\u001b[39m ImageViewer(\n\u001b[0;32m    381\u001b[0m             caption\u001b[39m=\u001b[39mcaption,\n\u001b[0;32m    382\u001b[0m             height\u001b[39m=\u001b[39mSCREEN_HEIGHT,\n\u001b[0;32m    383\u001b[0m             width\u001b[39m=\u001b[39mSCREEN_WIDTH,\n\u001b[0;32m    384\u001b[0m         )\n\u001b[0;32m    385\u001b[0m     \u001b[39m# show the screen on the image viewer\u001b[39;00m\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscreen)\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscreen\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\nes_py\\_image_viewer.py:148\u001b[0m, in \u001b[0;36mImageViewer.show\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m    140\u001b[0m image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpyglet\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mImageData(\n\u001b[0;32m    141\u001b[0m     frame\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[0;32m    142\u001b[0m     frame\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    145\u001b[0m     pitch\u001b[39m=\u001b[39mframe\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m\n\u001b[0;32m    146\u001b[0m )\n\u001b[0;32m    147\u001b[0m \u001b[39m# send the image to the window\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m image\u001b[39m.\u001b[39;49mblit(\u001b[39m0\u001b[39;49m, \u001b[39m0\u001b[39;49m, width\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_window\u001b[39m.\u001b[39;49mwidth, height\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_window\u001b[39m.\u001b[39;49mheight)\n\u001b[0;32m    149\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_window\u001b[39m.\u001b[39mflip()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\__init__.py:904\u001b[0m, in \u001b[0;36mImageData.blit\u001b[1;34m(self, x, y, z, width, height)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mblit\u001b[39m(\u001b[39mself\u001b[39m, x, y, z\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, width\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, height\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m--> 904\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_texture()\u001b[39m.\u001b[39mblit(x, y, z, width, height)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\__init__.py:835\u001b[0m, in \u001b[0;36mImageData.get_texture\u001b[1;34m(self, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_texture\u001b[39m(\u001b[39mself\u001b[39m, rectangle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, force_rectangle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    833\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_texture \u001b[39mor\u001b[39;00m\n\u001b[0;32m    834\u001b[0m             (\u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_texture\u001b[39m.\u001b[39m_is_rectangle \u001b[39mand\u001b[39;00m force_rectangle)):\n\u001b[1;32m--> 835\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_texture \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_texture(Texture, rectangle, force_rectangle)\n\u001b[0;32m    836\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_texture\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\__init__.py:821\u001b[0m, in \u001b[0;36mImageData.create_texture\u001b[1;34m(self, cls, rectangle, force_rectangle)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[39m\"\"\"Create a texture containing this image.\u001b[39;00m\n\u001b[0;32m    799\u001b[0m \n\u001b[0;32m    800\u001b[0m \u001b[39mIf the image's dimensions are not powers of 2, a TextureRegion of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[39m:rtype: cls or cls.region_class\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    820\u001b[0m internalformat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_internalformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat)\n\u001b[1;32m--> 821\u001b[0m texture \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mcreate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwidth, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheight, internalformat,\n\u001b[0;32m    822\u001b[0m                      rectangle, force_rectangle)\n\u001b[0;32m    823\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchor_x \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchor_y:\n\u001b[0;32m    824\u001b[0m     texture\u001b[39m.\u001b[39manchor_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manchor_x\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\__init__.py:1465\u001b[0m, in \u001b[0;36mTexture.create\u001b[1;34m(cls, width, height, internalformat, rectangle, force_rectangle, min_filter, mag_filter)\u001b[0m\n\u001b[0;32m   1462\u001b[0m     texture_height \u001b[39m=\u001b[39m _nearest_pow2(height)\n\u001b[0;32m   1464\u001b[0m \u001b[39mid\u001b[39m \u001b[39m=\u001b[39m GLuint()\n\u001b[1;32m-> 1465\u001b[0m glGenTextures(\u001b[39m1\u001b[39;49m, byref(\u001b[39mid\u001b[39;49m))\n\u001b[0;32m   1466\u001b[0m glBindTexture(target, \u001b[39mid\u001b[39m\u001b[39m.\u001b[39mvalue)\n\u001b[0;32m   1467\u001b[0m glTexParameteri(target, GL_TEXTURE_MIN_FILTER, min_filter)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\gl\\lib.py:87\u001b[0m, in \u001b[0;36merrcheck\u001b[1;34m(result, func, arguments)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mGLException\u001b[39;00m(\u001b[39mException\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39merrcheck\u001b[39m(result, func, arguments):\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m _debug_gl_trace:\n\u001b[0;32m     89\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# done flag tells us whether or not we need to restart the game\n",
    "done = True\n",
    "for step in range(100000):\n",
    "    if done:\n",
    "        env.reset() # This starts the game from the initial start state\n",
    "    # The step function allows the agent to take the supplied action. \n",
    "    # .sample() chooses a random action from the action space within the environment and passes that into the step()\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    # render will show the game on the screen\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close() # use this standalone line to close the environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2: Preprocess the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "# Import Matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FrameStack, imported above, allows us to store several frames of the game at a time. This is important because if you look at a single frame of the game, you have no idea what the state actually is. If Mario is in the air, is he jumping? Falling? Wearing anti-gravity boots? Having a 'memory' of the last few frames of the game allows better interpretation of how you got to the state you are in. If Mario was lower in a previous frame than the current one, it can be inferred he is probably jumping at this point. \n",
    "\n",
    "The GrayScaleObservation cuts down the amount of information that the model is trying to process. If we didn't do that, we would be getting back 3 color channels from the game (Red, Blue, Green) and the model would look at all 3 when trying to learn from the current state. There is already a lot going on so if we cut down to a simplified black and white version, the agent will have one less thing that it needs to iterate over.\n",
    "\n",
    "MatPlotLib is not necessary but will be used to show the benefits of frame stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the states shape: (240, 256, 3). Notice the 3 on the end, we have not grayscaled yet so you can see there are three channels, one per color\n",
      "After grayscaling, you can see the shape ((240, 256, 1)) now has a 1 on the end. We have reduced one of the dimensions of data down by 2/3rds!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Create base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "\n",
    "# 2. Simplify the controls with the SIMPLE_MOVEMENT action space\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "state = env.reset()\n",
    "print(f\"Here is the states shape: {state.shape}. Notice the 3 on the end, we have not grayscaled yet so you can see there are three channels, one per color\")\n",
    "plt.imshow(state)\n",
    "# 3. Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True) # keep_dim=True keeps the final 1 on the end of that shape, which we need to allow for frame stacking\n",
    "gs_state = env.reset()\n",
    "print(f\"After grayscaling, you can see the shape ({gs_state.shape}) now has a 1 on the end. We have reduced one of the dimensions of data down by 2/3rds!\")\n",
    "plt.imshow(gs_state)\n",
    "# 4. Wrap inside the dummy environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# 5. Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    state, reward, done, info = env.step([env.action_space.sample()])\n",
    "\n",
    "# print(state.shape[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "for idx in range(state.shape[3]):\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import OS for file path management\n",
    "import os\n",
    "# Import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is blatantly copied from the tutorial, it allows you to save your model on x number of steps. \n",
    "# This is optional but if you want to be able to examine how the model behaves at certain points or after\n",
    "# a certain number of training iterations, this is nice to have.\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, starting_point, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.starting_point = starting_point\n",
    "    \n",
    "    def _initcallback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if (self.n_calls+self.starting_point) % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls+self.starting_point))\n",
    "            self.model.save(model_path)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we make up directories that you want to save your training data to and log files. You can name these whatever you want.\n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CHECKPOINT_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gex71\\Documents\\repos\\mario-ml\\mario-tutorial.ipynb Cell 21\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Setup model saving callback\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m callback \u001b[39m=\u001b[39m TrainAndLoggingCallback(check_freq\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, save_path\u001b[39m=\u001b[39mCHECKPOINT_DIR, starting_point\u001b[39m=\u001b[39m\u001b[39m10000\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CHECKPOINT_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR, starting_point=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# This is a temp model that gets created once so you can start training\n",
    "# PPO stands for Proximal Policy Optimization\n",
    "# CNN Policies are for images\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, n_steps=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/PPO_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv-v2\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 152 |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 3   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 30            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022499822 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0191        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 156           |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | -0.000509     |\n",
      "|    value_loss           | 478           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 24            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 63            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5897054e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0236        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.181         |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 0.000128      |\n",
      "|    value_loss           | 2.58          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 21            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 94            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7677201e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.00245      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.128         |\n",
      "|    n_updates            | 220           |\n",
      "|    policy_gradient_loss | 3.12e-05      |\n",
      "|    value_loss           | 1.16          |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 20            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8944807e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0807        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0751        |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -5.45e-05     |\n",
      "|    value_loss           | 0.693         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.461749e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0334       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.147        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | 7.98e-05     |\n",
      "|    value_loss           | 0.752        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 19           |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 184          |\n",
      "|    total_timesteps      | 3584         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.046143e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0581       |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -2.65e-05    |\n",
      "|    value_loss           | 0.414        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 19            |\n",
      "|    iterations           | 8             |\n",
      "|    time_elapsed         | 214           |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6489102e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | -0.0106       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0688        |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -0.000367     |\n",
      "|    value_loss           | 0.273         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 18            |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 244           |\n",
      "|    total_timesteps      | 4608          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.4280784e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.94         |\n",
      "|    explained_variance   | 0.0268        |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.102         |\n",
      "|    n_updates            | 270           |\n",
      "|    policy_gradient_loss | -0.000161     |\n",
      "|    value_loss           | 0.248         |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 18           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 275          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.778577e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.0552       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 46.8         |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.000109    |\n",
      "|    value_loss           | 73.3         |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x276f055a310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model, this is how it learns\n",
    "# If you dont want to do the callback method, you can just remove it as it can create a lot of files that take up a lot of space\n",
    "model.learn(total_timesteps=5000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the current model, as a manual save do the following line\n",
    "# model.save('testNameForTheModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model (this is so we can either test or continue training from that point)\n",
    "# PPO stands for Proximal Policy Optimization\n",
    "model = PPO.load('./train/best_model_4000000')\n",
    "model.set_env(env) # Uncomment this to set the environment when doing continual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gex71\\Documents\\repos\\mario-ml\\mario-tutorial.ipynb Cell 26\u001b[0m line \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X34sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X34sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X34sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(state)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X34sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:50\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\n\u001b[0;32m     45\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     46\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[np\u001b[39m.\u001b[39mndarray, Dict[\u001b[39mstr\u001b[39m, np\u001b[39m.\u001b[39mndarray]], np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mndarray, List[Dict[\u001b[39mstr\u001b[39m, Any]],]:\n\u001b[0;32m     48\u001b[0m     observations, rewards, dones, infos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvenv\u001b[39m.\u001b[39mstep_wait()\n\u001b[1;32m---> 50\u001b[0m     observations, infos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstackedobs\u001b[39m.\u001b[39;49mupdate(observations, dones, infos)\n\u001b[0;32m     52\u001b[0m     \u001b[39mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\stacked_observations.py:143\u001b[0m, in \u001b[0;36mStackedObservations.update\u001b[1;34m(self, observations, dones, infos)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstackedobs[:, \u001b[39m-\u001b[39mobservations\u001b[39m.\u001b[39mshape[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_dimension] :, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m observations\n\u001b[0;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstackedobs[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, \u001b[39m-\u001b[39mobservations\u001b[39m.\u001b[39mshape[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstack_dimension] :] \u001b[39m=\u001b[39m observations\n\u001b[0;32m    144\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstackedobs, infos\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Actually test the model!! \n",
    "\n",
    "# Start the game\n",
    "state = env.reset()\n",
    "while True:\n",
    "    # \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the states shape: (240, 256, 3). Notice the 3 on the end, we have not grayscaled yet so you can see there are three channels, one per color\n",
      "After grayscaling, you can see the shape ((240, 256, 1)) now has a 1 on the end. We have reduced one of the dimensions of data down by 2/3rds!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n",
      "c:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\gex71\\Documents\\repos\\mario-ml\\mario-tutorial.ipynb Cell 28\u001b[0m line \u001b[0;36m<cell line: 67>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m state \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     \u001b[39m# \u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     action, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     state, reward, done, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/gex71/Documents/repos/mario-ml/mario-tutorial.ipynb#X36sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     env\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:579\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\n\u001b[0;32m    560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    561\u001b[0m     observation: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    564\u001b[0m     deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    565\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[np\u001b[39m.\u001b[39mndarray, Optional[Tuple[np\u001b[39m.\u001b[39mndarray, \u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m]]]:\n\u001b[0;32m    566\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    567\u001b[0m \u001b[39m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[0;32m    568\u001b[0m \u001b[39m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[39m        (used in recurrent policies)\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy\u001b[39m.\u001b[39;49mpredict(observation, state, episode_start, deterministic)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[1;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[0;32m    335\u001b[0m observation, vectorized_env \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobs_to_tensor(observation)\n\u001b[0;32m    337\u001b[0m \u001b[39mwith\u001b[39;00m th\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 338\u001b[0m     actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(observation, deterministic\u001b[39m=\u001b[39;49mdeterministic)\n\u001b[0;32m    339\u001b[0m \u001b[39m# Convert to numpy\u001b[39;00m\n\u001b[0;32m    340\u001b[0m actions \u001b[39m=\u001b[39m actions\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:630\u001b[0m, in \u001b[0;36mActorCriticPolicy._predict\u001b[1;34m(self, observation, deterministic)\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, observation: th\u001b[39m.\u001b[39mTensor, deterministic: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m    623\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[39m    Get the action according to the policy for a given observation.\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[39m    :return: Taken action according to the policy\u001b[39;00m\n\u001b[0;32m    629\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_distribution(observation)\u001b[39m.\u001b[39mget_actions(deterministic\u001b[39m=\u001b[39mdeterministic)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:657\u001b[0m, in \u001b[0;36mActorCriticPolicy.get_distribution\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_distribution\u001b[39m(\u001b[39mself\u001b[39m, obs: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Distribution:\n\u001b[0;32m    651\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[39m    Get the current policy distribution given the observations.\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \n\u001b[0;32m    654\u001b[0m \u001b[39m    :param obs:\u001b[39;00m\n\u001b[0;32m    655\u001b[0m \u001b[39m    :return: the action distribution.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 657\u001b[0m     features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_features(obs)\n\u001b[0;32m    658\u001b[0m     latent_pi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmlp_extractor\u001b[39m.\u001b[39mforward_actor(features)\n\u001b[0;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_action_dist_from_latent(latent_pi)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\policies.py:129\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures_extractor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mNo features extractor was set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    128\u001b[0m preprocessed_obs \u001b[39m=\u001b[39m preprocess_obs(obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobservation_space, normalize_images\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize_images)\n\u001b[1;32m--> 129\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_extractor(preprocessed_obs)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:93\u001b[0m, in \u001b[0;36mNatureCNN.forward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, observations: th\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m th\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcnn(observations))\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    138\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 139\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32mc:\\Users\\gex71\\miniconda3\\envs\\marioEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#With a fresh kernal restart the kernal if needed) just click this cell to run the model\n",
    "# Import Super Mario Bros game\n",
    "import gym_super_mario_bros\n",
    "# Import Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import simplified controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "# Import Matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "# Import OS for file path management\n",
    "import os\n",
    "# Import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# 1. Create base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "\n",
    "# 2. Simplify the controls with the SIMPLE_MOVEMENT action space\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "state = env.reset()\n",
    "print(f\"Here is the states shape: {state.shape}. Notice the 3 on the end, we have not grayscaled yet so you can see there are three channels, one per color\")\n",
    "plt.imshow(state)\n",
    "# 3. Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True) # keep_dim=True keeps the final 1 on the end of that shape, which we need to allow for frame stacking\n",
    "gs_state = env.reset()\n",
    "print(f\"After grayscaling, you can see the shape ({gs_state.shape}) now has a 1 on the end. We have reduced one of the dimensions of data down by 2/3rds!\")\n",
    "plt.imshow(gs_state)\n",
    "# 4. Wrap inside the dummy environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# 5. Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last')\n",
    "\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, starting_point, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "        self.starting_point = starting_point\n",
    "    \n",
    "    def _initcallback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if (self.n_calls+self.starting_point) % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls+self.starting_point))\n",
    "            self.model.save(model_path)\n",
    "        return True\n",
    "    \n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR, starting_point=10000)\n",
    "\n",
    "model = PPO.load('./train/best_model_1750000') # Change the file name here to pick a different model (if you have one)\n",
    "\n",
    "state = env.reset()\n",
    "while True:\n",
    "    # \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('marioEnv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "149ef2d2d860e9d106d1674b4750cb6920af6515ed341906ef3e43a4b04aa488"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
